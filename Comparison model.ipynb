{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Activation, LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae7330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "\n",
    "def look_back(X, a):\n",
    "    X_lb = np.zeros((len(X)- 29*a , a, 12))\n",
    "    for i in range(len(X) - 29 * a):\n",
    "        for j in range(a):\n",
    "            X_lb[i, j] = X[i+(j*29)]\n",
    "    X_lb = X_lb.reshape(int(len(X)/29) - a, 29, a, 12)\n",
    "    Y_lb = X[a*29:, 7]\n",
    "    Y_lb = Y_lb.reshape(int(len(X)/29) - a, 29, 1)\n",
    "    return X_lb, Y_lb\n",
    "\n",
    "def division(data):\n",
    "    train_size = int(len(data)*0.6)\n",
    "    val_size = int(len(data)*0.8)\n",
    "    data_train = data[0:train_size]\n",
    "    data_val = data[train_size:val_size]\n",
    "    data_test = data[val_size:len(data)]\n",
    "    return data_train, data_val, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data about best time step 5\n",
    "\n",
    "df = pd.read_csv('./data.csv', encoding='ms949')\n",
    "\n",
    "ts = 5\n",
    "\n",
    "train = df[:641*29]                    \n",
    "validation = df[len(train):1006*29]    \n",
    "test = df[len(train)+len(validation):] \n",
    "\n",
    "X_train, Y_train = look_back(train.values, ts)\n",
    "Y_train = Y_train.reshape(len(Y_train), 29, 1, 1)\n",
    "\n",
    "X_val, Y_val = look_back(validation.values, ts)\n",
    "Y_val = Y_val.reshape(len(Y_val), 29, 1, 1)\n",
    "\n",
    "X_test, Y_test = look_back(test.values, ts)\n",
    "Y_test = Y_test.reshape(len(Y_test), 29, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of water-quality stations\n",
    "\n",
    "stations = ['Goryeong','Naju', 'Nam River', 'Neungseo', 'Dalcheon', 'Lake Daecheong', 'Dogae', 'Lake Dongbok','Bokhacheon', 'Sinam', 'Andong Dam downstream', 'Yangpyeong', 'Yeoju', 'Lake Okjeong', 'Lake Yongdam', 'Yongbong', 'Uchi', 'Yugucheon', 'Lake Uiam', 'Jang-gye', 'Jeokpo', 'Lake Juam', 'Jiseokcheon', 'Cheongam', 'Chilgok', 'Lake Tamjin', 'Poongyang', 'Hyeondo', 'Hoesang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_lst = []\n",
    "r2_lst = []\n",
    "\n",
    "for i in tqdm(range(0, 29, 1)):\n",
    "    stst = datetime.datetime.now()\n",
    "    \n",
    "    trainX, valX, testX = X_train[:, i, :, :], X_val[:, i, :, :], X_test[:, i, :, :]\n",
    "    trainY, valY, testY = Y_train[:, i, :, :].reshape(-1), Y_val[:, i, :, :].reshape(-1), Y_test[:, i, :, :].reshape(-1)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 60, mode = 'min')\n",
    "    mc = ModelCheckpoint('./LSTM_{}.h5'.format(stations[i]), \n",
    "                         monitor='val_loss', \n",
    "                         mode='min', \n",
    "                         save_best_only=True)\n",
    "    \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(256, input_shape = (trainX.shape[1], trainX.shape[2]), return_sequences = True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    print(\"### Model training : time step_{} ###\".format(ts))\n",
    "    print('Start training :', datetime.datetime.now())\n",
    "    model.fit(trainX, trainY,\n",
    "              epochs=1000, \n",
    "              batch_size=8, \n",
    "              validation_data=(valX, valY), \n",
    "              callbacks=[early_stopping, mc],\n",
    "              verbose=0)\n",
    "    print('End training :', datetime.datetime.now())\n",
    "    \n",
    "    y_predicted = model.predict(testX)\n",
    "    y_predicted = y_predicted.reshape(-1, 1).astype('float32')\n",
    "    y_observed = testY.reshape(-1, 1).astype('float32')\n",
    "    \n",
    "\n",
    "    raw= {'Observed': list(y_observed), 'Predicted': list(y_predicted)}\n",
    "    rr = pd.DataFrame(raw)\n",
    "    reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "\n",
    "    try:\n",
    "        rmse = round(sqrt(mean_squared_error(y_predicted, )), 3)\n",
    "        r2 = round(reg.rsquared, 3)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    rmse_lst.append(rmse)\n",
    "    r2_lst.append(r2)\n",
    "    \n",
    "    print('RMSE :', rmse)\n",
    "    print('R-squared :', r2)\n",
    "    print(\"---------------------------------\\n\")\n",
    "    \n",
    "    del model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_predicted = model.predict(testX)\n",
    "    y_predicted = y_predicted.reshape(-1, 1).astype('float32')\n",
    "    y_observed = testY.reshape(-1, 1).astype('float32')\n",
    "    \n",
    "    raw= {'Observed': list(y_observed), 'Predicted': list(y_predicted)}\n",
    "    rr = pd.DataFrame(raw)\n",
    "    reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "\n",
    "    try:\n",
    "        rmse = round(sqrt(mean_squared_error(y_observed, y_predicted)), 3)\n",
    "        r2 = round(reg.rsquared, 3)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    rmse_lst.append(rmse)\n",
    "    r2_lst.append(r2)\n",
    "    \n",
    "    print('RMSE :', rmse)\n",
    "    print('R-squared :', r2)\n",
    "    print(\"---------------------------------\\n\")\n",
    "    \n",
    "    del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf113]",
   "language": "python",
   "name": "conda-env-tf113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
